{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define random seeds for deterministic results\n",
    "seed = 4242\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "csv = pd.read_csv('training_w_labels1.csv')\n",
    "texts = csv['title'].values\n",
    "labels = csv['type_1_positive_change_+1week'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples: 55035\n",
      "labels: 55035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff71303b860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('examples:', len(texts))\n",
    "print('labels:', len(labels))\n",
    "\n",
    "sns.histplot(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_weights(labels, return_dict=True, first_class_index=0):\n",
    "    if isinstance(labels[0], list) or isinstance(labels[0], np.ndarray):\n",
    "        labels = [y.argmax() for y in labels]\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(labels), y=labels)\n",
    "    if return_dict:\n",
    "        weight_dict = {}\n",
    "        for key in range(len(class_weights)):\n",
    "            weight_dict[key + first_class_index] = class_weights[key]\n",
    "        return weight_dict\n",
    "    else:\n",
    "        return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data restrictions\n",
    "vocabulary = 10000\n",
    "length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer texts (filters for punctuation)\n",
    "tokenizer = Tokenizer(num_words=vocabulary)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "#if save_model:\n",
    "#    torch.save(tokenizer, f'models/{model_name}.tokenizer')\n",
    "\n",
    "# tansform texts to padded sequences\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences = pad_sequences(sequences, maxlen=length, truncating='post', padding='pre')\n",
    "\n",
    "# compute balanced class weights if needed\n",
    "#class_weights = calculate_class_weights(labels=labels)\n",
    "\n",
    "# train / test split and shuffle\n",
    "x_train, x_test, y_train, y_test = train_test_split(sequences, labels, random_state=seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayDataSet(Dataset):\n",
    "    def __init__(self, x, y, t):\n",
    "        self.X = torch.tensor(x, dtype=t)\n",
    "        self.Y = torch.tensor(y, dtype=t)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.Y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# setup data loaders for training and evaluation\n",
    "train_loader = DataLoader(dataset=ArrayDataSet(x=x_train, y=y_train, t=torch.long),\n",
    "                          batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "valid_loader = DataLoader(dataset=ArrayDataSet(x=x_test, y=y_test, t=torch.long),\n",
    "                          batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 200\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocabulary, embedding_dim=features)\n",
    "        self.convolutions = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(5, features)),\n",
    "                                           nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(11, features)),\n",
    "                                           nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(17, features)),\n",
    "                                           nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(25, features)),\n",
    "                                           nn.Conv2d(in_channels=1, out_channels=64, kernel_size=(32, features))])\n",
    "        self.fc1 = nn.Linear(in_features=64 * len(self.convolutions), out_features=32)\n",
    "        self.fc2 = nn.Linear(in_features=32, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.unsqueeze(x, dim=1)\n",
    "        xs = []\n",
    "        for convolution in self.convolutions:\n",
    "            c = F.softplus(convolution(x))\n",
    "            c = torch.squeeze(c)\n",
    "            c = F.max_pool1d(c, kernel_size=c.size()[2])\n",
    "            xs.append(c)\n",
    "        x = torch.cat(xs, dim=2)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.leaky_relu(self.fc1(x), negative_slope=0.1)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMNet, self).__init__()\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocabulary, embedding_dim=features)\n",
    "        self.lstm_1 = nn.LSTM(input_size=features, hidden_size=32, num_layers=3, dropout=0.125,\n",
    "                              bidirectional=True, batch_first=True)\n",
    "        # self.lstm_2 = nn.LSTM(input_size=32 * length, hidden_size=32, num_layers=1, dropout=0.125,\n",
    "        #                       bidirectional=True, batch_first=True)\n",
    "        #self.fc1 = nn.Linear(in_features=256, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.embeddings(x)\n",
    "        # print(x.shape)\n",
    "        x, _ = self.lstm_1(x)\n",
    "        # print(x.shape)\n",
    "        x = x[:, -1, :]\n",
    "        # h = torch.cat(h, dim=1)\n",
    "        # print('h:', h.shape)\n",
    "        # print(x.shape)\n",
    "        # x = x.reshape(x.shape[0], -1)\n",
    "        # print(x.shape)\n",
    "        # x, h = self.lstm_2(x)\n",
    "        # print(x.shape)\n",
    "        #x = self.fc1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' # change to cpu for cpu and cuda for gpu training\n",
    "net = LSTMNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 2])\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(batch_size, length).long().to(device)\n",
    "p = net(t)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.001, alpha=0.9, eps=1e-07)\n",
    "#class_weights = torch.tensor(list(class_weights.values())).type(torch.FloatTensor).cuda()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "#loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    net.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, batch in enumerate(valid_loader):\n",
    "            x_batch, y_batch = batch\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            # make predictions\n",
    "            predictions = net(x_batch)\n",
    "            # get loss\n",
    "            loss = loss_function(predictions, y_batch)\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # count correct predictions\n",
    "            predicted_classes = torch.max(predictions.data, dim=1)[1]\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted_classes == y_batch).sum().item()\n",
    "\n",
    "    net.train()\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.85%[epoch:   1] train_loss:   0.011 - train_acc:   53.50% | val_loss:   0.011 - val_acc:   54.80%\n",
      "66.86%"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "accuracies = []\n",
    "losses = []\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_index, batch in enumerate(train_loader):\n",
    "        sys.stdout.write(f'\\r{batch_index / len(train_loader) * 100:4.2f}%')\n",
    "        sys.stdout.flush()\n",
    "        x_batch, y_batch = batch\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # make predictions\n",
    "        predictions = net(x_batch)\n",
    "        # get loss\n",
    "        loss = loss_function(predictions, y_batch)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # calculate gradients using the loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # perform optimizer step on the network parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # count correct predictions\n",
    "        predicted_classes = torch.max(predictions.data, dim=1)[1]\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted_classes == y_batch).sum().item()\n",
    "\n",
    "    epoch_loss, epoch_acc = evaluate()\n",
    "    result = f'[epoch: {epoch + 1:3d}] train_loss: {running_loss / total:7.3f}'\n",
    "    result += f' - train_acc: {100 * correct / total:7.2f}% |'\n",
    "    result += f' val_loss: {epoch_loss:7.3f} - val_acc: {100 * epoch_acc:7.2f}%'\n",
    "    print(result)\n",
    "\n",
    "    accuracies.append(correct / total)\n",
    "    losses.append(running_loss / total)\n",
    "    val_accuracies.append(epoch_acc)\n",
    "    val_losses.append(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
